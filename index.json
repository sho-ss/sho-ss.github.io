[{"authors":["admin"],"categories":null,"content":"とある企業でデータサイエンティストをしています．\n学部生・院生のときは様々な研究テーマを浅く拾ってしまっていたので，向こう数年は一つの領域をしっかり勉強したいと思っています． このブログでは，自分が勉強した内容をまとめていきます．\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://sho-ss.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"とある企業でデータサイエンティストをしています． 学部生・院生のときは様々な研究テーマを浅く拾ってしまっていたので，向こう数年は一つの領域をし","tags":null,"title":"Sho Shimoyama (下山 翔)","type":"author"},{"authors":null,"categories":["位相"],"content":" はじめに 本稿では，位相空間論の中でコンパクト性に関係する内容を簡単にまとめます．\n「代数幾何と学習理論（渡辺先生 著）」を読んでいる時にコンパクトという単語が前半の章でちょこちょこ出現するのですが，全然イメージがつかず，イメージをつけたいなと思ったのが本稿を作成したきっかけです．\n本文では，可読性向上のため，ですます調からである調に変えます．\n目次  位相空間の基礎からコンパクトまで  開集合形と位相空間 コンパクト  コンパクトに関する種々の事柄  コンパクトである/でない集合の例 コンパクトであることの嬉さ  参考  位相空間の基礎からコンパクトまで 本章では，諸概念の定義をまとめる． [1],[2],[5]を参照した．\nなぜそのような概念を考えるのか，それがあると何が嬉しいのかについては次章以降にまとめる．\n開集合形と位相空間 $X$ を集合とする．\n$X$ の部分集合からなる族 $\\mathcal{O}$ が開集合形であるとは次の3条件が成り立つことである．\n1) $\\mathcal{O}$ の元からなる族 $\\{U_{\\lambda}\\}_{\\lambda \\in \\Lambda}$ ($\\Lambda$は添え字集合) について， \\begin{align} \\bigcup_{\\lambda \\in \\Lambda} O_\\lambda \\in \\mathcal{O} \\end{align} 2) $k\\in \\mathbb{N}$, $O_1, \\ldots, O_k \\in \\mathcal{O}$ について， \\begin{align} \\bigcap_{i =1}^k O_i \\in \\mathcal{O} \\end{align} 3) $\\phi$ を空集合とし， \\begin{align} X, \\phi \\in \\mathcal{O} \\end{align} このとき，組 $(X, \\mathcal{O})$ を位相空間，$\\mathcal{O}$ の元を開集合という．\nコンパクト $(X, \\mathcal{O})$ を位相空間とする．\n部分集合 $F \\subset X$ がコンパクトであるとは，次が成り立つことである．\n$\\mathcal{O}$ の元からなる族 $\\{O_{\\lambda}\\}_{\\lambda \\in \\Lambda}$ で $F \\subset \\bigcup_{\\lambda \\in \\Lambda} O_\\lambda$ となるものを選んだとき\n（i.e. $\\mathcal{O}$ の元からなる，$F$ の任意の開被覆 $\\{O_{\\lambda}\\}_{\\lambda \\in \\Lambda}$ に対して），\nある $k \\in \\mathbb{N}$ と $\\lambda_1, \\ldots, \\lambda_k$ が存在して，$F \\subset \\bigcup_{i=1}^k O_{\\lambda_i}$ が成り立つ．\nコンパクトに関する種々の事柄 この章では，コンパクトである/でない集合の具体例，コンパクトという性質が成り立つことの嬉さについてまとめる． [3], [4]を参照した．\nコンパクトである/でない集合の例 1) $X = \\{ \\frac{1}{n} | n \\in \\mathbb{N} \\} \\cup \\{0\\}$ はコンパクト．\n証明： $X$ の任意の開被覆を $\\{O_\\lambda\\}_{\\lambda \\in \\Lambda}$（$O_\\lambda \\subset \\mathbb{R}$）とおく．\nある $\\lambda_0$ が存在して，$0 \\in O_{\\lambda_0}$ が成り立つ．\n$O_{\\lambda_0}$ は開集合なので，ある $\\delta \u0026gt; 0$ が存在して，$(-\\delta, \\delta) \\subset O_{\\lambda_0}$．\n$k \\in \\mathcal{N}$ を $\\frac{1}{k} \u0026lt; \\delta$ となるように取れば，$n \\geq k$ に対して，$\\frac{1}{n} \\in O_{\\lambda_0}$．\n$n \\leq k - 1$に対して，各 $n$ に対しある $\\lambda_n$ が存在して $\\frac{1}{n} \\in O_{\\lambda_n}$ が成り立つ．\nしたがって，$X$ は有限個の開集合 $O_{\\lambda_0}, O_{\\lambda_1}, \\ldots, O_{\\lambda_{k-1}}$ で覆うことができるので，コンパクトである．\n2) $\\mathbb{R}$はコンパクトでない．\n証明： $O_r = (-|r|, |r|)$ とすると，$\\bigcup_{r \\in \\mathbb{R}} O_r$ は $\\mathbb{R}$ の開被覆である．\n$\\mathbb{R}$ がコンパクトであるとすると，$\\mathbb{R} = \\bigcup_{i=1}^k O_{r_i}$ となる有限個の開集合 $O_{r_1}, \\ldots, O_{r_k}$ が存在する．\n$k$ は有限なので添え字の最大値が取れて，それを $r\u0026rsquo; = \\max \\{r_1, \\ldots, r_k\\}$ とする．\nこのとき，$\\mathbb{R} = \\bigcup_{i=1}^k O_{r_i} = (-|r\u0026rsquo;|, |r\u0026rsquo;|)$ となり矛盾する．\nよって，$\\mathbb{R}$ はコンパクトでない．\nコンパクトであることの嬉さ コンパクト集合上の関数に対して次の2つが成り立つ[3]．\n コンパクト集合上の連続関数は最大値と最小値を持つ コンパクト集合上の連続関数は一様連続である  また，歴史的な背景としても，閉区間上の関数は一様連続であることを証明するためにコンパクト性が用いられたようである[4]．\n「コンパクト集合上の連続関数は最大値と最小値を持つ」の証明 $X$ をコンパクトな集合，$X$ 上の実数値連続関数を $f:X \\to \\mathbb{R}$ とする．\n\\begin{align} U_r = f^{-1}\\left( ( -|r| - 1, |r| + 1) \\right) = \\left\\{x \\in X | f(x) \\in ( -|r| - 1, |r| + 1)\\right\\} \\end{align} とすると，$f$ は連続であるので $U_r$ は開集合である．\nしたがって，$\\{U_r\\}_{r \\in \\mathbb{R}}$ は $X$ の開被覆である．\n$X$ はコンパクトなので，有限個の $U_{r_1}, \\ldots, U_{r_k}$ が存在し，$X \\subset \\bigcup_{i = 1}^k U_{r_i}$ とできる．\nしたがって， \\begin{align} f(X) \\subset f\\left( \\bigcup_{i = 1}^k U_{r_i} \\right) = \\left( - \\max_i |r_i| - 1, \\max_i |r_i| + 1 \\right) \\end{align} となり，$f(X)$は有界集合である．\nWeierstrassの上限・下限の存在定理から，$f(X)$ は上限 $\\sup f(X) = M$ と下限 $\\inf f(X) = m$ を持つ．\n$F_n = f^{-1} \\left([M - \\frac{1}{n}, M] \\right)$ と定義すると，上限の定義から $M - \\frac{1}{n} \u0026lt; f(x) \\leq M$ を満たす $x \\in X$ が存在するので，$F_n \\neq \\phi$．\n$f$ は連続関数なので $F_n$ は閉集合である．\nそして，$F_1 \\supset F_2 \\supset \\cdots \\supset F_n$ より，$\\bigcap_{i=1}^n F_i \\neq \\phi$（i.e. 有限交叉性を満たす）．\nコンパクト集合であることと，閉集合の族 $\\{F_n\\}_{n \\in \\mathbb{N}}$ が有限交叉性を満たすならば $\\bigcap_{n \\in \\mathbb{N}} F_n \\neq \\phi$が成り立つことは同値である（後述）．\nしたがって，任意の $n$ に対して，$M - \\frac{1}{n} \u0026lt; f(x) \\leq M$ を満たす $x \\in X$ が存在するので，$M$ は最大値である．\n最小値に対しても同様の議論で証明できる．\nコンパクトと有限交叉性に関して 次の2つは同値である．\n $(X, \\mathcal{O})$ を位相空間とする．$X$ はコンパクトである． $(X, \\mathcal{O})$ を位相空間とする．$(X, \\mathcal{O})$ 上の閉集合の族 $\\{F\\}_{F \\in \\mathcal{F}}$ が有限性を持つならば $\\bigcap_{F \\in \\mathcal{F}} F \\neq \\phi$  $1 \\Rightarrow 2$ の証明：$\\{F\\}_{F \\in \\mathcal{F}}$ が有限交叉性を持つとする．\n$\\bigcap_{F \\in \\mathcal{F}} F = \\phi$ であるなら， \\begin{align} X = X \\setminus \\bigcap_{F \\in \\mathcal{F}} F = \\bigcup_{F \\in \\mathcal{F}} F^c \\end{align} ただし，$F^c = X \\setminus F$．\n$F^c$ は開集合であるので，$\\bigcup_{F \\in \\mathcal{F}} F^c$ は $X$ の開被覆である．\n$X$ はコンパクトなので，有限個の $F_1^c, \\ldots, F_k^c$ が選べて，$X = \\bigcup_{i=1}^k F_i^c$ とできる．\nよって， \\begin{align} \\phi = X \\setminus \\bigcup_{i=1}^k F_i^c = \\bigcap_{i=1}^k F_i \\end{align} が成り立つ．\nこれは，$\\{F\\}_{F \\in \\mathcal{F}}$ が有限交叉性を持つことと矛盾する．\nしたがって，$\\bigcap_{F \\in \\mathcal{F}} F \\neq \\phi$．\n$2 \\Rightarrow 1$ の証明：$X$ の開被覆を $\\{O_\\lambda\\}_{\\lambda \\in \\Lambda}$ とする．\n2 が成り立つことから，その対偶も成り立つ．すなわち，$\\bigcap_{F \\in \\mathcal{F}} F = \\phi$ なら，ある有限個の閉集合 $F_1, \\ldots, F_k$ が存在して，$\\bigcap_{i=1}^k F_i = \\phi$ とできる．\n\\begin{align} \\phi = X \\setminus \\bigcup_{\\lambda \\in \\Lambda} O_\\lambda = \\bigcap_{\\lambda \\in \\Lambda} O_\\lambda^c \\end{align} より，$\\bigcap_{i=1}^k O_{\\lambda_i}^c = \\phi$ となる，ある有限個の $O_{\\lambda_1}^c, \\ldots, O_{\\lambda_k}^c$ が存在する．\nよって， \\begin{align} X = X \\setminus \\bigcap_{i=1}^k O_{\\lambda_i}^c = \\bigcup_{i=1}^k O_{\\lambda_i} \\end{align} が成り立つ．\n∴ $X$ はコンパクトである．\n「コンパクト集合上の連続関数は一様連続である」の証明 ここでは，距離空間上での証明を行う．\n位相空間上で一様連続を定義するためには，空間の位相構造だけでは不十分で，一様構造という構造をいれる必要があるらしい．参考．\n$(X, d)$ を距離空間，$U \\subset X$ を $X$ のコンパクトな部分集合，$f: U \\to \\mathbb{R}$ を $U$ 上の実数値連続関数とする．\nまず，連続関数と一様連続の定義を示す．\n一様連続\nある部分集合 $V$ 上の実数値関数 $f: V \\to \\mathbb{R}$ が一様連続であるとは，次が成り立つことである．\n$\\forall \\epsilon \u0026gt; 0$ に対しある $\\delta_\\epsilon \u0026gt; 0$ が存在して，$d(x, y) \u0026lt; \\delta_\\epsilon$ を満たす任意の $x, y \\in V$ に対して $|f(x) - f(y)| \u0026lt; \\delta_\\epsilon $ とできる．\n連続\nある部分集合 $V$ 上の実数値関数 $f: V \\to \\mathbb{R}$ が連続であるとは，次が成り立つことである．\n$\\forall x \\in V$ と $\\forall \\epsilon \u0026gt; 0$ に対しある $\\delta_{x, \\epsilon} \u0026gt; 0$ が存在して，$d(x, y) \u0026lt; \\delta_{x, \\epsilon}$ を満たす任意の $y \\in V$ に対して $|f(x) - f(y)| \u0026lt; \\epsilon $ とできる．\n連続は $x$ に依存しているが，一様連続は $x$ と $y$ の距離にのみ依存している．\n命題の証明： 任意の $\\epsilon \u0026gt; 0$ と各 $x \\in U$ に対して $V_x = \\{ y \\in U | d(x, y) \u0026lt; \\frac{1}{2} \\delta_{x, \\epsilon} \\}$ と定義する．\n$\\{V_x\\}_{x \\in U}$ は $U$ の開被覆であり，$U$ はコンパクトなので，$U = \\bigcup_{i=1}^k V_{x_i}$ となる有限個の開集合 $V_{x_1}, \\ldots, V_{x_k}$ が選べる．\nよって，$\\delta\u0026rsquo;_\\epsilon = \\frac{1}{2} \\min \\{\\delta_{x_1, \\epsilon}, \\ldots, \\delta_{x_k, \\epsilon} \\}$ とできて，$\\delta\u0026rsquo;_\\epsilon \u0026gt; 0$ である．\n$d(x, y) \u0026lt; \\delta\u0026rsquo;_\\epsilon$ となる任意の $x, y \\in U$ を考える．\nコンパクト性より，ある $x_i \\ (i \\in \\{1,\\ldots, k\\})$ が存在して，$x \\in V_{x_i}$ である．\n定義より $\\delta\u0026rsquo;_\\epsilon \\leq \\frac{1}{2} \\delta_{x_i, \\epsilon}$ であるから， \\begin{align} d(y, x_i) \u0026amp; \\leq d(y, x) + d(x, x_i) \u0026lt; \\delta\u0026rsquo;_\\epsilon + \\frac{1}{2} \\delta_{x_i, \\epsilon} \\leq \\delta_{x_i, \\epsilon} \\end{align} よって，$f$ の連続性から $|f(y) - f(x_i)| \u0026lt; \\epsilon$ が成り立ち， \\begin{align} |f(x) - f(y)| \\leq |f(x) - f(x_i)| + |f(x_i) - f(y)| \u0026lt; 2\\epsilon \\end{align} $\\epsilon$ は任意であるから，$\\epsilon\u0026rsquo; = 2\\epsilon$ とできる．\nよって，$d(x, y) \u0026lt; \\delta\u0026rsquo;_{\\epsilon\u0026rsquo;}$ を満たす任意の $x,y \\in U$ に対して，$|f(x) - f(y)| \u0026lt; \\epsilon\u0026rsquo;$ が成り立つことが証明された．\n以上から，命題が成り立つことが証明された．\n参考 [1]: 【VRアカデミア】距離空間と位相空間その２ 位相空間【曲直瀬おめが。】\n[2]: 【VRアカデミア】距離空間と位相空間その３ コンパクト性【曲直瀬おめが。】\n[3]: 有界閉とコンパクト pdf資料\n[4]: 微分幾何学講義ノート \n[5]: [位相への30講 (数学30講シリーズ)]\n","date":1596346568,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596346568,"objectID":"5f41492c53a58f8b4c020f3827ba6fef","permalink":"https://sho-ss.github.io/post/math/topology_compact/","publishdate":"2020-08-02T14:36:08+09:00","relpermalink":"/post/math/topology_compact/","section":"post","summary":"はじめに 本稿では，位相空間論の中でコンパクト性に関係する内容を簡単にまとめます． 「代数幾何と学習理論（渡辺先生 著）」を読んでいる時にコンパク","tags":["数学","位相"],"title":"位相におけるコンパクトとは何か","type":"post"},{"authors":null,"categories":["GPML"],"content":" 問1 Squared Exponential Kernel を用いたGPの事前分布と事後分布からサンプルした関数をプロットせよ． Squared Exponential Kernelの式は以下で定義される． $$ K(\\mathbf{x}_{p}, \\mathbf{x}_{q}) = \\exp(-\\frac{1}{2} | \\mathbf{x}_{p} - \\mathbf{x}_{q} |^2) $$\nA. import numpy as np from scipy.spatial.distance import cdist import matplotlib.pyplot as plt def squared_exponential(X1, X2): r = cdist(X1, X2) return np.exp( - 0.5 * r**2) def get_posterior_params(X, Xstar, y): print('X: ', X.shape) print('Xstar: ', Xstar.shape) cov_test_train = squared_exponential(Xstar, X) cov_train = squared_exponential(X, X) cov_test = squared_exponential(Xstar, Xstar) cov_inv = np.linalg.inv(cov_train) term1 = np.dot(cov_test_train, cov_inv) mean = np.dot(term1, y) cov = cov_test - np.dot(term1, np.transpose(cov_test_train)) return mean, cov fig = plt.figure(figsize=(15, 6)) ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2) X = np.linspace(-5, 5, 100) X_t = X.reshape(-1, 1) # prior cov_matrix = squared_exponential(X_t, X_t) Ys = np.random.multivariate_normal(np.zeros(len(cov_matrix)), cov_matrix, size=3) cov = np.diag(cov_matrix) for Y in Ys: ax1.plot(X, Y) mean = np.zeros(len(X)) ax1.fill_between(X, mean+2*cov, mean-2*cov, alpha=.3, color='gray') ax1.set_ylim(-2.3, 2.3) ax1.set_xlim(-5, 5) ax1.set_xlabel('input, x', fontsize=18) ax1.set_ylabel('output, f(x)', fontsize=18) ax1.tick_params(labelsize=18) # posterior X_observed = np.array([-4, -3, -1, 0, 2]).reshape(-1, 1) Y_observed = np.array([-2, 0, 1, 2, -1]).reshape(-1, 1) mean, cov = get_posterior_params(X_observed, X_t, Y_observed) Ys = np.random.multivariate_normal(mean[:, 0], cov, size=3) for Y in Ys: ax2.plot(X, Y) ax2.scatter(X_observed, Y_observed, marker='+', color='black', s=200) cov = np.diag(cov) ax2.fill_between(X, mean[:,0]+2*cov, mean[:,0]-2*cov, alpha=.3, color='gray') ax2.set_ylim(-2.5, 2.5) ax2.set_xlim(-5, 5) ax2.set_xlabel('input, x', fontsize=18) ax2.set_ylabel('output, f(x)', fontsize=18) ax2.tick_params(labelsize=18) plt.savefig('./log/sample.png', dpi=200)  ","date":1553224790,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553224790,"objectID":"7ecea7702eb7d5e30df4be5feec5d6d6","permalink":"https://sho-ss.github.io/post/gpml/section2/","publishdate":"2019-03-22T12:19:50+09:00","relpermalink":"/post/gpml/section2/","section":"post","summary":"問1 Squared Exponential Kernel を用いたGPの事前分布と事後分布からサンプルした関数をプロットせよ． Squared Exponential Kernelの式は以下で定義される． $$ K(\\mathbf{x}_{p}, \\mathbf{x}_{q}) = \\exp(-\\frac{1}{2} | \\mathbf{x}_{p} - \\mathbf{x}_{q} |^2) $$","tags":["GPML"],"title":"Section2 answer","type":"post"},{"authors":null,"categories":["論文"],"content":" はじめに 論文へのリンク\nモチベーション one-shot architecture searchにおける重み共有について分析したい． 重み共有では構造間で重みを共有して学習を行うが， 様々な構造に対して同一の重み集合を利用してなぜ上手くいくのか．\n概要 モデルはCNNを用いている． 探索空間内の操作を全て含んだone-shotモデルを学習する． これは，重み共有を用いた学習と同じである． ここで操作とは 1$\\times$1conv や 3$\\times$3conv，maxpool などである． 本項ではこれを large one-shot モデルと記す． 学習後の large one-shot モデルから操作のいくつかを取り除き，予測精度の変化を計測する．\n以下の図のように操作を全て含んだモデルを学習する． 先行研究との差 MorphNetはフィルタサイズを対象としている． 一方，提案手法は操作の枝狩りやスキップコネクションに焦点を当てている．\nデータセット CIFAR-10とImageNetを使用．\n結果 weight sharing の役割に対する洞察 構造をサンプリングして，large one-shot モデルから対応する構造を持つモデルを得る． このモデルを単に one-shot モデルと記す． サンプリングした構造を持つ，一から学習したモデルがstand-aloneモデル．\nFigure5は，one-shot モデルと stand-alone モデルの精度の関係を表している． one-shot において精度の高い構造は一から学習しても精度が高くなっており，large one-shot は「構造の良さ」を学習できていると考えられる． また，one-shot における精度差と stand-alone における精度差から，large one-shot は精度への影響が大きい操作の欠落に対して敏感であると思われる．\nこの結果から，「重み共有は操作が性能に与える影響をモデルに識別させる役割がある」と仮定する．\n上述の仮定を示すために，探索空間内のほぼ全ての操作が有効になっている構造 (参照構造) の予測分布と 一部の操作のみが有効になっている構造 (候補構造) の予測分布の間で symmetric KL-divergence を計測する． 論文ではクラス分類を対象としているためモデルの出力は確率分布とみなせる．\nFigure6は，サンプリングした各構造の精度，それらの構造と参照構造との KL-divergence の関係を表している． 精度が高い構造の予測分布は参照構造の予測分布と近しくなることが確認できる． つまり，large one-shot モデルはどの操作が予測性能への影響が大きいかを学習していると考えることができる．\n以上から，重み共有は操作が性能に与える影響をモデルに識別させる役割があると考える．\n  \n手法の性能 Table1 は提案手法 (One-Shot Top, One-Shot Small)と one-shot 学習の枠組みで捉えられる既存手法 (SMASH, ENAS)，ランダムサーチ (Random) それぞれの結果を比較したものである．\nOne-Shot Top はランダムにサンプリングした構造の中で large one-shot において良好な性能を示した上位 10 の構造を用いて， 最初の畳み込み層にサイズ$F$のフィルターを追加して一から学習したモデルである．\nOne-Shot Small はサンプリングした構造の内 large one-shot での精度が閾値を超えた構造の中で最小のパラメータ数を持つ構造を用いて， 最初の畳み込み層にサイズ$F$のフィルターを追加して一から学習したモデルである．\nAll On は全ての操作を含んだ構造を用いて，最初の畳み込み層にサイズ$F$のフィルターを追加して一から学習したモデルである．\nTop，Small と比べると All on は精度差が1%であるが，パラメータ数は大幅に増加している． このことから，architecture search は精度への影響が弱い操作の枝狩りとみなすことができる．\n提案手法は SMASH や Cell search 以外のすべての ENAS 手法と競合している． これは one-shot 学習では hypernet work や controller を必要としないことを示唆している．\n ","date":1552277119,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552277119,"objectID":"337b56125b2a3c8312ea2753dc9b9f82","permalink":"https://sho-ss.github.io/post/understand_oneshot/my-article-name/","publishdate":"2019-03-11T13:05:19+09:00","relpermalink":"/post/understand_oneshot/my-article-name/","section":"post","summary":"はじめに 論文へのリンク モチベーション one-shot architecture searchにおける重み共有について分析したい． 重み共有では構造間で重みを共有して学習を行うが， 様々","tags":["論文","NAS"],"title":"Understanding and Simplifying One-Shot Architecture Search まとめ","type":"post"}]